{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1972b9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from cvxopt import matrix\n",
    "from cvxopt import solvers\n",
    "from libsvm.svmutil import *\n",
    "from pathlib import Path\n",
    "from sklearn.svm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18dca285",
   "metadata": {},
   "outputs": [],
   "source": [
    "class0 = list()\n",
    "path0 = 'svm/train/0/'\n",
    "for image in Path(path0).glob('*.jpg'):\n",
    "    image_resized = np.array(Image.open(image).resize((16, 16))).flatten()/255\n",
    "    class0.append(image_resized)\n",
    "label0 = np.array(class0) \n",
    "\n",
    "class1 = list()\n",
    "path1 = 'svm/train/1/'\n",
    "for image in Path(path1).glob('*.jpg'):\n",
    "    image_resized = np.array(Image.open(image).resize((16, 16))).flatten()/255\n",
    "    class1.append(image_resized)\n",
    "label1 = np.array(class1)\n",
    "\n",
    "class2 = list()\n",
    "path2 = 'svm/train/2/'\n",
    "for image in Path(path2).glob('*.jpg'):\n",
    "    image_resized = np.array(Image.open(image).resize((16, 16))).flatten()/255\n",
    "    class2.append(image_resized)\n",
    "label2 = np.array(class2) \n",
    "\n",
    "class3 = list()\n",
    "path3 = 'svm/train/3/'\n",
    "for image in Path(path3).glob('*.jpg'):\n",
    "    image_resized = np.array(Image.open(image).resize((16, 16))).flatten()/255\n",
    "    class3.append(image_resized)\n",
    "label3 = np.array(class3) \n",
    "\n",
    "class4 = list()\n",
    "path4 = 'svm/train/4/'\n",
    "for image in Path(path4).glob('*.jpg'):\n",
    "    image_resized = np.array(Image.open(image).resize((16, 16))).flatten()/255\n",
    "    class4.append(image_resized)\n",
    "label4 = np.array(class4) \n",
    "\n",
    "class5 = list()\n",
    "path5 = 'svm/train/5/'\n",
    "for image in Path(path5).glob('*.jpg'):\n",
    "    image_resized = np.array(Image.open(image).resize((16, 16))).flatten()/255\n",
    "    class5.append(image_resized)\n",
    "label5 = np.array(class5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dc794c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = np.full((2380, 1), fill_value=0, dtype='double')\n",
    "y1 = np.full((2380, 1), fill_value=1, dtype='double')\n",
    "y2 = np.full((2380, 1), fill_value=2, dtype='double')\n",
    "y3 = np.full((2380, 1), fill_value=3, dtype='double')\n",
    "y4 = np.full((2380, 1), fill_value=4, dtype='double')\n",
    "y5 = np.full((2380, 1), fill_value=5, dtype='double')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34dcd6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dict = {}\n",
    "y_dict = {}\n",
    "\n",
    "x_dict[0] = label0\n",
    "x_dict[1] = label1\n",
    "x_dict[2] = label2\n",
    "x_dict[3] = label3\n",
    "x_dict[4] = label4\n",
    "x_dict[5] = label5\n",
    "\n",
    "y_dict[0] = y0\n",
    "y_dict[1] = y1\n",
    "y_dict[2] = y2\n",
    "y_dict[3] = y3\n",
    "y_dict[4] = y4\n",
    "y_dict[5] = y5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e48b6ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vclass0 = list()\n",
    "vpath0 = 'svm/val/0/'\n",
    "for image in Path(vpath0).glob('*.jpg'):\n",
    "    image_resized = np.array(Image.open(image).resize((16, 16))).flatten()/255\n",
    "    vclass0.append(image_resized)\n",
    "vlabel0 = np.array(vclass0) \n",
    "\n",
    "vclass1 = list()\n",
    "vpath1 = 'svm/val/1/'\n",
    "for image in Path(vpath1).glob('*.jpg'):\n",
    "    image_resized = np.array(Image.open(image).resize((16, 16))).flatten()/255\n",
    "    vclass1.append(image_resized)\n",
    "vlabel1 = np.array(vclass1)\n",
    "\n",
    "vclass2 = list()\n",
    "vpath2 = 'svm/val/2/'\n",
    "for image in Path(vpath2).glob('*.jpg'):\n",
    "    image_resized = np.array(Image.open(image).resize((16, 16))).flatten()/255\n",
    "    vclass2.append(image_resized)\n",
    "vlabel2 = np.array(vclass2) \n",
    "\n",
    "vclass3 = list()\n",
    "vpath3 = 'svm/val/3/'\n",
    "for image in Path(vpath3).glob('*.jpg'):\n",
    "    image_resized = np.array(Image.open(image).resize((16, 16))).flatten()/255\n",
    "    vclass3.append(image_resized)\n",
    "vlabel3 = np.array(vclass3)\n",
    "\n",
    "vclass4 = list()\n",
    "vpath4 = 'svm/val/4/'\n",
    "for image in Path(vpath4).glob('*.jpg'):\n",
    "    image_resized = np.array(Image.open(image).resize((16, 16))).flatten()/255\n",
    "    vclass4.append(image_resized)\n",
    "vlabel4 = np.array(vclass4) \n",
    "\n",
    "vclass5 = list()\n",
    "vpath5 = 'svm/val/5/'\n",
    "for image in Path(vpath5).glob('*.jpg'):\n",
    "    image_resized = np.array(Image.open(image).resize((16, 16))).flatten()/255\n",
    "    vclass5.append(image_resized)\n",
    "vlabel5 = np.array(vclass5)\n",
    "\n",
    "vy0 = np.full((vlabel0.shape[0], 1), fill_value=0, dtype='double')\n",
    "vy1 = np.full((vlabel1.shape[0], 1), fill_value=1, dtype='double')\n",
    "vy2 = np.full((vlabel2.shape[0], 1), fill_value=2, dtype='double')\n",
    "vy3 = np.full((vlabel3.shape[0], 1), fill_value=3, dtype='double')\n",
    "vy4 = np.full((vlabel4.shape[0], 1), fill_value=4, dtype='double')\n",
    "vy5 = np.full((vlabel5.shape[0], 1), fill_value=5, dtype='double')\n",
    "\n",
    "vx = np.concatenate((vlabel0, vlabel1))\n",
    "vx = np.concatenate((vx, vlabel2))\n",
    "vx = np.concatenate((vx, vlabel3))\n",
    "vx = np.concatenate((vx, vlabel4))\n",
    "vx = np.concatenate((vx, vlabel5))\n",
    "\n",
    "vy = np.concatenate((vy0, vy1))\n",
    "vy = np.concatenate((vy, vy2))\n",
    "vy = np.concatenate((vy, vy3))\n",
    "vy = np.concatenate((vy, vy4))\n",
    "vy = np.concatenate((vy, vy5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "083d27af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1372549  0.16078431 0.07843137 ... 0.3254902  0.44313725 0.17254902]\n",
      " [0.29803922 0.37647059 0.22745098 ... 0.34509804 0.28627451 0.17647059]\n",
      " [0.21176471 0.32156863 0.23921569 ... 0.30588235 0.30588235 0.25490196]\n",
      " ...\n",
      " [0.35686275 0.54901961 0.81960784 ... 0.27843137 0.41960784 0.18039216]\n",
      " [0.96078431 0.97647059 0.98823529 ... 0.27058824 0.24705882 0.23921569]\n",
      " [0.05098039 0.34901961 0.57254902 ... 0.24313725 0.23529412 0.25882353]]\n",
      "[[3.]\n",
      " [3.]\n",
      " [3.]\n",
      " ...\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.concatenate((x_dict[1], x_dict[0])))\n",
    "print(np.concatenate((y_dict[3], y_dict[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f9448d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.full((4760, 1), fill_value=-1, dtype='double')\n",
    "c = 1\n",
    "G = np.concatenate((np.identity(4760, dtype='double'), np.identity(4760, dtype='double')*(-1)))\n",
    "h = np.concatenate((np.full((4760, 1), fill_value=c, dtype='double'), np.zeros((4760, 1), dtype='double')))\n",
    "b = np.zeros((1,1), dtype='double')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1e04fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_cvxopt(x, y, label1, label2):\n",
    "    for i in range(0, 4760):\n",
    "        if(y[i][0]==label1):\n",
    "            y[i][0]=-1\n",
    "        else:\n",
    "            y[i][0]=1\n",
    "\n",
    "    P = np.empty((4760, 4760), dtype='double')\n",
    "    gamma = 0.001\n",
    "    for i in range(0, 4760):\n",
    "        for j in range(0, 4760):\n",
    "            P[i][j] = y[i][0]*y[j][0]*np.exp(-gamma * np.linalg.norm(np.asarray(x[i])-np.asarray(x[j])))\n",
    "    A = y.reshape((1, 4760))\n",
    "\n",
    "    sol = solvers.qp(matrix(P), matrix(q), matrix(G), matrix(h), matrix(A), matrix(b))\n",
    "    optimal_alpha = np.array(sol['x'])\n",
    "    alpha = np.where(optimal_alpha<0.0001, 0, optimal_alpha)\n",
    "\n",
    "    temp = np.empty((4760, 4760))\n",
    "    for i in range(0, 4760):\n",
    "        for j in range(0, 4760):\n",
    "            temp[i][j] = alpha[i][0]*y[i][0]*np.exp(-gamma * np.linalg.norm(np.asarray(x[i])-np.asarray(x[j])))\n",
    "    train_wTx = np.asarray(np.sum(temp, axis=0))\n",
    "\n",
    "    all_b = train_wTx.reshape((4760, 1))\n",
    "    b_opt = -0.5*(np.max(all_b[np.where(y==-1) and np.where(alpha!=0)], axis=0) + np.min(all_b[np.where(y==1) and np.where(alpha!=0)], axis=0))\n",
    "\n",
    "    vtemp = np.empty((x.shape[0], vx.shape[0]))\n",
    "    for i in range(0, x.shape[0]):\n",
    "        for j in range(0, vx.shape[0]):\n",
    "            vtemp[i][j] = alpha[i][0]*y[i][0]*np.exp(-gamma * np.linalg.norm(np.asarray(x[i])-np.asarray(vx[j])))\n",
    "    valid_wTx = np.asarray(np.sum(vtemp, axis=0))\n",
    "\n",
    "    y_pred = list()\n",
    "    for i in range(0, vy.shape[0]):\n",
    "        val = label2 if(valid_wTx[i] + b_opt)>0 else label1\n",
    "        y_pred.append(int(val))\n",
    "\n",
    "    return np.array(y_pred, dtype='int').reshape((1200,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13827815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.3494e+03 -1.3356e+04  6e+04  3e+00  1e-12\n",
      " 1: -1.6273e+03 -9.1778e+03  8e+03  2e-12  1e-12\n",
      " 2: -1.9247e+03 -2.9406e+03  1e+03  3e-12  1e-12\n",
      " 3: -2.2161e+03 -2.4992e+03  3e+02  4e-12  1e-12\n",
      " 4: -2.2792e+03 -2.4301e+03  2e+02  8e-13  1e-12\n",
      " 5: -2.3224e+03 -2.3755e+03  5e+01  3e-12  1e-12\n",
      " 6: -2.3384e+03 -2.3560e+03  2e+01  2e-12  1e-12\n",
      " 7: -2.3453e+03 -2.3479e+03  3e+00  1e-12  1e-12\n",
      " 8: -2.3464e+03 -2.3466e+03  2e-01  4e-12  1e-12\n",
      " 9: -2.3465e+03 -2.3465e+03  6e-03  2e-12  1e-12\n",
      "10: -2.3465e+03 -2.3465e+03  1e-04  7e-13  1e-12\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.5464e+03 -1.2189e+04  4e+04  2e+00  1e-12\n",
      " 1: -2.6772e+03 -8.3096e+03  6e+03  6e-13  2e-12\n",
      " 2: -3.1282e+03 -3.7725e+03  6e+02  1e-12  1e-12\n",
      " 3: -3.4090e+03 -3.5725e+03  2e+02  3e-12  2e-12\n",
      " 4: -3.4817e+03 -3.5204e+03  4e+01  1e-12  2e-12\n",
      " 5: -3.4979e+03 -3.5077e+03  1e+01  2e-12  2e-12\n",
      " 6: -3.5024e+03 -3.5042e+03  2e+00  5e-14  2e-12\n",
      " 7: -3.5033e+03 -3.5034e+03  2e-01  2e-13  2e-12\n",
      " 8: -3.5034e+03 -3.5034e+03  4e-03  2e-13  2e-12\n",
      " 9: -3.5034e+03 -3.5034e+03  7e-05  2e-12  2e-12\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.4242e+03 -1.2123e+04  6e+04  3e+00  7e-13\n",
      " 1: -9.2384e+02 -7.9146e+03  7e+03  2e-02  9e-13\n",
      " 2: -1.1932e+03 -2.1790e+03  1e+03  3e-03  8e-13\n",
      " 3: -1.4109e+03 -1.7887e+03  4e+02  9e-04  8e-13\n",
      " 4: -1.4938e+03 -1.6582e+03  2e+02  3e-04  8e-13\n",
      " 5: -1.5291e+03 -1.6065e+03  8e+01  1e-04  8e-13\n",
      " 6: -1.5480e+03 -1.5797e+03  3e+01  5e-05  8e-13\n",
      " 7: -1.5559e+03 -1.5688e+03  1e+01  2e-05  8e-13\n",
      " 8: -1.5602e+03 -1.5632e+03  3e+00  3e-06  9e-13\n",
      " 9: -1.5614e+03 -1.5618e+03  4e-01  2e-07  9e-13\n",
      "10: -1.5616e+03 -1.5616e+03  9e-03  4e-09  9e-13\n",
      "11: -1.5616e+03 -1.5616e+03  2e-04  7e-11  9e-13\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.7857e+03 -1.2136e+04  4e+04  2e+00  1e-12\n",
      " 1: -2.8550e+03 -8.3023e+03  5e+03  2e-12  2e-12\n",
      " 2: -3.3459e+03 -3.9807e+03  6e+02  4e-13  1e-12\n",
      " 3: -3.5930e+03 -3.7997e+03  2e+02  1e-12  2e-12\n",
      " 4: -3.6701e+03 -3.7393e+03  7e+01  2e-12  2e-12\n",
      " 5: -3.6977e+03 -3.7171e+03  2e+01  2e-12  2e-12\n",
      " 6: -3.7061e+03 -3.7101e+03  4e+00  4e-12  2e-12\n",
      " 7: -3.7080e+03 -3.7085e+03  5e-01  1e-12  2e-12\n",
      " 8: -3.7082e+03 -3.7083e+03  1e-02  6e-14  2e-12\n",
      " 9: -3.7082e+03 -3.7083e+03  3e-04  1e-12  2e-12\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.5487e+03 -1.2425e+04  6e+04  3e+00  7e-13\n",
      " 1: -1.0266e+03 -8.2450e+03  8e+03  3e-02  9e-13\n",
      " 2: -1.2947e+03 -2.3420e+03  1e+03  4e-03  8e-13\n",
      " 3: -1.5235e+03 -1.9076e+03  4e+02  1e-03  8e-13\n",
      " 4: -1.6056e+03 -1.7814e+03  2e+02  5e-04  8e-13\n",
      " 5: -1.6414e+03 -1.7305e+03  9e+01  2e-04  8e-13\n",
      " 6: -1.6633e+03 -1.6990e+03  4e+01  6e-05  8e-13\n",
      " 7: -1.6713e+03 -1.6876e+03  2e+01  2e-05  8e-13\n",
      " 8: -1.6771e+03 -1.6802e+03  3e+00  3e-06  9e-13\n",
      " 9: -1.6783e+03 -1.6786e+03  3e-01  1e-07  9e-13\n",
      "10: -1.6785e+03 -1.6785e+03  1e-02  4e-09  9e-13\n",
      "11: -1.6785e+03 -1.6785e+03  2e-04  5e-11  1e-12\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.3359e+03 -1.2546e+04  5e+04  3e+00  1e-12\n",
      " 1: -2.3992e+03 -8.5919e+03  6e+03  2e-12  2e-12\n",
      " 2: -2.8004e+03 -3.5810e+03  8e+02  1e-12  1e-12\n",
      " 3: -3.1071e+03 -3.2918e+03  2e+02  7e-13  1e-12\n",
      " 4: -3.1835e+03 -3.2291e+03  5e+01  2e-12  2e-12\n",
      " 5: -3.1982e+03 -3.2167e+03  2e+01  2e-12  1e-12\n",
      " 6: -3.2061e+03 -3.2095e+03  3e+00  7e-13  2e-12\n",
      " 7: -3.2077e+03 -3.2080e+03  3e-01  9e-13  2e-12\n",
      " 8: -3.2079e+03 -3.2079e+03  1e-02  4e-13  2e-12\n",
      " 9: -3.2079e+03 -3.2079e+03  3e-04  1e-12  2e-12\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.2750e+03 -1.1248e+04  3e+04  2e+00  1e-12\n",
      " 1: -3.3329e+03 -7.6415e+03  4e+03  1e-12  2e-12\n",
      " 2: -3.9640e+03 -4.4595e+03  5e+02  3e-12  2e-12\n",
      " 3: -4.0807e+03 -4.3809e+03  3e+02  4e-13  2e-12\n",
      " 4: -4.1741e+03 -4.3043e+03  1e+02  3e-12  2e-12\n",
      " 5: -4.2131e+03 -4.2730e+03  6e+01  5e-12  2e-12\n",
      " 6: -4.2286e+03 -4.2601e+03  3e+01  3e-12  2e-12\n",
      " 7: -4.2377e+03 -4.2524e+03  1e+01  8e-14  2e-12\n",
      " 8: -4.2436e+03 -4.2472e+03  4e+00  3e-12  2e-12\n",
      " 9: -4.2453e+03 -4.2457e+03  4e-01  2e-12  2e-12\n",
      "10: -4.2455e+03 -4.2455e+03  3e-02  2e-12  2e-12\n",
      "11: -4.2455e+03 -4.2455e+03  9e-04  3e-12  2e-12\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.0221e+03 -1.3146e+04  6e+04  3e+00  8e-13\n",
      " 1: -1.3451e+03 -8.9534e+03  8e+03  2e-02  1e-12\n",
      " 2: -1.6393e+03 -2.6582e+03  1e+03  3e-03  9e-13\n",
      " 3: -1.9235e+03 -2.2293e+03  3e+02  6e-04  1e-12\n",
      " 4: -2.0034e+03 -2.1306e+03  1e+02  2e-04  1e-12\n",
      " 5: -2.0370e+03 -2.0891e+03  5e+01  7e-05  1e-12\n",
      " 6: -2.0536e+03 -2.0689e+03  2e+01  2e-05  1e-12\n",
      " 7: -2.0594e+03 -2.0621e+03  3e+00  1e-06  1e-12\n",
      " 8: -2.0606e+03 -2.0607e+03  2e-01  5e-08  1e-12\n",
      " 9: -2.0606e+03 -2.0607e+03  5e-03  1e-09  1e-12\n",
      "10: -2.0607e+03 -2.0607e+03  8e-05  2e-11  1e-12\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.1914e+03 -1.1766e+04  4e+04  2e+00  1e-12\n",
      " 1: -3.1746e+03 -8.0563e+03  5e+03  2e-12  2e-12\n",
      " 2: -3.7513e+03 -4.2848e+03  5e+02  3e-12  2e-12\n",
      " 3: -3.9414e+03 -4.1642e+03  2e+02  8e-13  2e-12\n",
      " 4: -4.0152e+03 -4.1079e+03  9e+01  2e-12  2e-12\n",
      " 5: -4.0471e+03 -4.0827e+03  4e+01  4e-12  2e-12\n",
      " 6: -4.0572e+03 -4.0747e+03  2e+01  5e-13  2e-12\n",
      " 7: -4.0633e+03 -4.0696e+03  6e+00  4e-12  2e-12\n",
      " 8: -4.0662e+03 -4.0671e+03  9e-01  2e-12  2e-12\n",
      " 9: -4.0666e+03 -4.0667e+03  3e-02  1e-12  2e-12\n",
      "10: -4.0667e+03 -4.0667e+03  6e-04  1e-13  2e-12\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.9124e+03 -1.2139e+04  4e+04  2e+00  1e-12\n",
      " 1: -2.9241e+03 -8.3276e+03  5e+03  6e-12  2e-12\n",
      " 2: -3.4291e+03 -4.0791e+03  7e+02  2e-12  2e-12\n",
      " 3: -3.6972e+03 -3.8706e+03  2e+02  3e-12  2e-12\n",
      " 4: -3.7725e+03 -3.8116e+03  4e+01  5e-12  2e-12\n",
      " 5: -3.7864e+03 -3.8005e+03  1e+01  5e-13  2e-12\n",
      " 6: -3.7925e+03 -3.7953e+03  3e+00  2e-12  2e-12\n",
      " 7: -3.7939e+03 -3.7941e+03  2e-01  6e-13  2e-12\n",
      " 8: -3.7940e+03 -3.7940e+03  5e-03  4e-12  2e-12\n",
      " 9: -3.7940e+03 -3.7940e+03  1e-04  5e-12  2e-12\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.6711e+03 -1.1903e+04  4e+04  2e+00  1e-12\n",
      " 1: -2.8196e+03 -8.0828e+03  5e+03  6e-12  2e-12\n",
      " 2: -3.3002e+03 -3.9546e+03  7e+02  3e-12  2e-12\n",
      " 3: -3.5621e+03 -3.7468e+03  2e+02  2e-12  2e-12\n",
      " 4: -3.6330e+03 -3.6896e+03  6e+01  2e-12  2e-12\n",
      " 5: -3.6527e+03 -3.6733e+03  2e+01  2e-12  2e-12\n",
      " 6: -3.6619e+03 -3.6653e+03  3e+00  6e-12  2e-12\n",
      " 7: -3.6635e+03 -3.6638e+03  3e-01  3e-12  2e-12\n",
      " 8: -3.6637e+03 -3.6637e+03  6e-03  8e-13  2e-12\n",
      " 9: -3.6637e+03 -3.6637e+03  1e-04  7e-12  2e-12\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.8775e+03 -1.2998e+04  5e+04  3e+00  1e-12\n",
      " 1: -2.1227e+03 -8.9273e+03  7e+03  3e-12  1e-12\n",
      " 2: -2.4569e+03 -3.3232e+03  9e+02  6e-13  1e-12\n",
      " 3: -2.7788e+03 -2.9530e+03  2e+02  2e-12  1e-12\n",
      " 4: -2.8536e+03 -2.8892e+03  4e+01  4e-13  1e-12\n",
      " 5: -2.8689e+03 -2.8751e+03  6e+00  1e-12  2e-12\n",
      " 6: -2.8716e+03 -2.8725e+03  8e-01  1e-12  1e-12\n",
      " 7: -2.8720e+03 -2.8721e+03  6e-02  4e-12  2e-12\n",
      " 8: -2.8721e+03 -2.8721e+03  1e-03  2e-12  2e-12\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6878e+03 -1.3113e+04  6e+04  3e+00  1e-12\n",
      " 1: -1.9932e+03 -9.0291e+03  7e+03  3e-12  1e-12\n",
      " 2: -2.3345e+03 -3.2619e+03  9e+02  2e-12  1e-12\n",
      " 3: -2.6651e+03 -2.8958e+03  2e+02  7e-13  1e-12\n",
      " 4: -2.7482e+03 -2.8181e+03  7e+01  1e-12  1e-12\n",
      " 5: -2.7746e+03 -2.7919e+03  2e+01  3e-12  1e-12\n",
      " 6: -2.7809e+03 -2.7856e+03  5e+00  2e-12  1e-12\n",
      " 7: -2.7829e+03 -2.7835e+03  5e-01  3e-12  1e-12\n",
      " 8: -2.7832e+03 -2.7832e+03  3e-02  3e-12  1e-12\n",
      " 9: -2.7832e+03 -2.7832e+03  6e-04  2e-12  2e-12\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6347e+03 -1.1882e+04  4e+04  2e+00  1e-12\n",
      " 1: -2.0168e+03 -7.8895e+03  6e+03  1e-12  1e-12\n",
      " 2: -2.3470e+03 -3.1625e+03  8e+02  7e-13  1e-12\n",
      " 3: -2.6165e+03 -2.8471e+03  2e+02  4e-13  1e-12\n",
      " 4: -2.7002e+03 -2.7574e+03  6e+01  8e-13  1e-12\n",
      " 5: -2.7188e+03 -2.7382e+03  2e+01  1e-12  1e-12\n",
      " 6: -2.7267e+03 -2.7298e+03  3e+00  1e-12  1e-12\n",
      " 7: -2.7281e+03 -2.7283e+03  2e-01  1e-12  1e-12\n",
      " 8: -2.7282e+03 -2.7282e+03  1e-02  6e-13  1e-12\n",
      " 9: -2.7282e+03 -2.7282e+03  2e-04  1e-12  2e-12\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.2181e+03 -1.2106e+04  4e+04  2e+00  1e-12\n",
      " 1: -2.4479e+03 -8.1849e+03  6e+03  1e-12  2e-12\n",
      " 2: -2.8525e+03 -3.5641e+03  7e+02  9e-13  1e-12\n",
      " 3: -3.1700e+03 -3.2968e+03  1e+02  6e-13  2e-12\n",
      " 4: -3.2262e+03 -3.2557e+03  3e+01  6e-13  2e-12\n",
      " 5: -3.2396e+03 -3.2451e+03  5e+00  2e-12  2e-12\n",
      " 6: -3.2424e+03 -3.2429e+03  5e-01  7e-12  2e-12\n",
      " 7: -3.2426e+03 -3.2427e+03  1e-02  5e-12  2e-12\n",
      " 8: -3.2426e+03 -3.2426e+03  3e-04  2e-13  2e-12\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "y_pred_cvxopt = np.empty((6, 6, 1200), dtype='int')\n",
    "\n",
    "for i in range(0, 6):\n",
    "    for j in range(0, i):\n",
    "        y_pred_cvxopt[i][j] = svm_cvxopt(np.concatenate((x_dict[i], x_dict[j])), np.concatenate((y_dict[i], y_dict[j])), i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbd8b03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 1 0 1]\n",
      "[0 2 0 ... 0 0 0]\n",
      "[2 2 1 ... 1 2 1]\n",
      "[3 0 0 ... 0 0 0]\n",
      "[3 1 1 ... 1 3 1]\n",
      "[3 2 2 ... 3 3 3]\n",
      "[0 0 4 ... 0 0 0]\n",
      "[4 4 1 ... 1 1 1]\n",
      "[4 2 4 ... 4 4 4]\n",
      "[3 4 4 ... 4 3 4]\n",
      "[0 5 5 ... 5 5 0]\n",
      "[1 5 1 ... 1 5 1]\n",
      "[2 2 5 ... 5 5 5]\n",
      "[3 5 5 ... 5 5 5]\n",
      "[4 5 5 ... 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 6):\n",
    "    for j in range(0, i):\n",
    "        print(y_pred_cvxopt[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7ed0b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 1200):\n",
    "    print(y_pred_cvxopt[2][0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b17e66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47833333333333333\n"
     ]
    }
   ],
   "source": [
    "y_pred_cvxopt_final = list()\n",
    "\n",
    "for k in range(0, 1200):\n",
    "    temp = [0, 0, 0, 0, 0, 0]\n",
    "    for i in range(0, 6):\n",
    "        for j in range(0, i):\n",
    "            ind = int(y_pred_cvxopt[i][j][k])\n",
    "            temp[ind] += 1\n",
    "    y_pred_cvxopt_final.append(np.array(temp).argmax())\n",
    "\n",
    "count_cvxopt = 0\n",
    "for i in range(0, vy.shape[0]):\n",
    "    if(y_pred_cvxopt_final[i] == vy[i]):\n",
    "        count_cvxopt += 1\n",
    "print(count_cvxopt/len(y_pred_cvxopt_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7afb1fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_svc(x, y, label1, label2):\n",
    "    guassian_model = SVC(kernel='rbf', C=1.0, gamma=0.001)\n",
    "    guassian_model.fit(x, y)\n",
    "    return np.array(guassian_model.predict(vx)).reshape((1200,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10eafe81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\samra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\samra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\samra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\samra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\samra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\samra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\samra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\samra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\samra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\samra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\samra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\samra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\samra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\samra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "y_pred_svc = np.empty((6, 6, 1200))\n",
    "\n",
    "for i in range(0, 6):\n",
    "    for j in range(0, i):\n",
    "        y_pred_svc[i][j] = svm_svc(np.concatenate((x_dict[i], x_dict[j])), np.concatenate((y_dict[i], y_dict[j])), i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c5935ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5608333333333333\n"
     ]
    }
   ],
   "source": [
    "y_pred_svc_final = list()\n",
    "\n",
    "for k in range(0, 1200):\n",
    "    temp = [0, 0, 0, 0, 0, 0]\n",
    "    for i in range(0, 6):\n",
    "        for j in range(0, i):\n",
    "            ind = int(y_pred_svc[i][j][k])\n",
    "            temp[ind] += 1\n",
    "    y_pred_svc_final.append(np.array(temp).argmax())\n",
    "\n",
    "count_svc = 0\n",
    "for i in range(0, vy.shape[0]):\n",
    "    if(y_pred_svc_final[i] == vy[i]):\n",
    "        count_svc += 1\n",
    "print(count_svc/len(y_pred_svc_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb2c4438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(prediction):\n",
    "    conf_mat = list()\n",
    "\n",
    "    for k in range(0, 6):\n",
    "        temp = [0, 0, 0, 0, 0, 0]    \n",
    "        for i in range(k*200, (k+1)*200):\n",
    "            temp[prediction[i]] += 1\n",
    "        conf_mat.append(temp)\n",
    "\n",
    "    return conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8656eb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39, 45, 33, 42, 23, 18], [2, 171, 4, 8, 5, 10], [5, 10, 119, 36, 23, 7], [14, 16, 23, 125, 16, 6], [9, 29, 65, 46, 46, 5], [16, 61, 22, 18, 9, 74]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred_cvxopt_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d28bbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[79, 21, 22, 24, 23, 31], [6, 154, 1, 5, 10, 24], [8, 4, 130, 25, 21, 12], [26, 6, 24, 128, 12, 4], [26, 16, 58, 36, 58, 6], [22, 23, 12, 7, 12, 124]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred_svc_final))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
